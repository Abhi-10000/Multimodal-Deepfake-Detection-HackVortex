{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGeDYh0VqTR6ZVpFkFh9lW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhi-10000/Multimodal-Deepfake-Detection-HackVortex/blob/main/version1%262.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAQ_G3fXUvZa",
        "outputId": "84c8dd28-59b3-447f-a72c-1a93f57022c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: python_speech_features in /usr/local/lib/python3.11/dist-packages (0.6)\n",
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (8.2.0)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (19.24.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from face_recognition) (11.2.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (2.2.2)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.6.1)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.3)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.7)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.4.26)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.5.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install moviepy face_recognition pydub librosa python_speech_features mediapipe scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "New section"
      ],
      "metadata": {
        "id": "LivyHqb1c0Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies (run this in Colab before running the code block below)\n",
        "# !pip install moviepy librosa opencv-python scikit-learn\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import librosa\n",
        "from moviepy.editor import VideoFileClip\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import joblib\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def extract_audio_and_frames(video_path, audio_out='extracted_audio.wav', frame_dir='frames', fps=5):\n",
        "    print(\"[Step 1] Extracting audio and frames from video...\")\n",
        "    clip = VideoFileClip(video_path)\n",
        "    clip.audio.write_audiofile(audio_out, logger=None)\n",
        "\n",
        "    if not os.path.exists(frame_dir):\n",
        "        os.makedirs(frame_dir)\n",
        "\n",
        "    duration = clip.duration\n",
        "    for i, t in enumerate(np.arange(0, duration, 1.0 / fps)):\n",
        "        frame = clip.get_frame(t)\n",
        "        frame_path = os.path.join(frame_dir, f\"frame_{i:03d}.jpg\")\n",
        "        cv2.imwrite(frame_path, cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    print(f\"Extracted {i+1} frames and saved audio as '{audio_out}'\")\n",
        "    return audio_out, frame_dir\n",
        "\n",
        "def extract_lip_movement_features(frame_dir):\n",
        "    print(\"[Step 2] Extracting lip movement features from frames...\")\n",
        "    mouth_movements = []\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "    for file in sorted(os.listdir(frame_dir)):\n",
        "        if file.endswith(\".jpg\"):\n",
        "            path = os.path.join(frame_dir, file)\n",
        "            img = cv2.imread(path)\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "            mouth_area = 0\n",
        "            for (x, y, w, h) in faces:\n",
        "                mouth_y = y + int(0.6 * h)\n",
        "                mouth_h = int(0.2 * h)\n",
        "                mouth = gray[mouth_y:mouth_y + mouth_h, x:x + w]\n",
        "                mouth_area = cv2.countNonZero(mouth)\n",
        "\n",
        "            mouth_movements.append(mouth_area)\n",
        "\n",
        "    print(f\"Extracted mouth movement data from {len(mouth_movements)} frames\")\n",
        "    return mouth_movements\n",
        "\n",
        "def extract_audio_features(audio_path, sr=16000):\n",
        "    print(\"[Step 3] Extracting MFCCs and audio energy...\")\n",
        "    y, sr = librosa.load(audio_path, sr=sr)\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    energy = np.sum(librosa.feature.rms(y=y), axis=1)\n",
        "    print(f\"Extracted MFCC shape: {mfccs.shape}, Energy length: {len(energy)}\")\n",
        "    return mfccs, energy\n",
        "\n",
        "def calculate_lipsync_inconsistency(mouth_movements, audio_energy):\n",
        "    print(\"[Step 4] Calculating lip-sync inconsistency...\")\n",
        "    length = min(len(mouth_movements), len(audio_energy))\n",
        "    if length < 2:\n",
        "        print(\"Insufficient data for correlation calculation\")\n",
        "        return 1.0  # High suspicion if insufficient data\n",
        "\n",
        "    mouth_movements = np.array(mouth_movements[:length])\n",
        "    audio_energy = np.array(audio_energy[:length])\n",
        "    corr, _ = pearsonr(mouth_movements, audio_energy)\n",
        "    print(f\"Lip-sync Pearson correlation: {corr:.3f}\")\n",
        "    return 1 - corr  # 1 = no sync, 0 = perfect sync\n",
        "\n",
        "def synthetic_voice_detection(mfccs):\n",
        "    print(\"[Step 5] Running synthetic voice detection...\")\n",
        "    mean_mfcc = np.mean(mfccs, axis=1)\n",
        "    std_mfcc = np.std(mfccs, axis=1)\n",
        "    features = np.concatenate((mean_mfcc, std_mfcc)).reshape(1, -1)\n",
        "\n",
        "    if os.path.exists(\"voice_model.pkl\"):\n",
        "        clf = joblib.load(\"voice_model.pkl\")\n",
        "    else:\n",
        "        # Mock classifier (for MVP demonstration)\n",
        "        X_dummy = np.random.rand(20, 26)\n",
        "        y_dummy = [0]*10 + [1]*10\n",
        "        clf = RandomForestClassifier()\n",
        "        clf.fit(X_dummy, y_dummy)\n",
        "        joblib.dump(clf, \"voice_model.pkl\")\n",
        "        print(\"Trained mock voice detection model\")\n",
        "\n",
        "    prob = clf.predict_proba(features)[0][1]\n",
        "    print(f\"Voice synthetic probability score: {prob:.3f}\")\n",
        "    return prob  # 0 = likely real, 1 = likely synthetic\n",
        "\n",
        "def calculate_overall_score(lipsync_score, voice_score, w1=0.6, w2=0.4):\n",
        "    print(\"[Step 6] Calculating weighted suspicion score...\")\n",
        "    print(f\"Lip-sync score: {lipsync_score:.3f}, Voice score: {voice_score:.3f}\")\n",
        "    return w1 * lipsync_score + w2 * voice_score\n",
        "\n",
        "def run_inference(video_path):\n",
        "    print(\"⏳ Starting inference pipeline...\")\n",
        "    audio, frames = extract_audio_and_frames(video_path)\n",
        "\n",
        "    lips = extract_lip_movement_features(frames)\n",
        "    mfccs, energy = extract_audio_features(audio)\n",
        "\n",
        "    lip_score = calculate_lipsync_inconsistency(lips, energy)\n",
        "    voice_score = synthetic_voice_detection(mfccs)\n",
        "\n",
        "    final_score = calculate_overall_score(lip_score, voice_score)\n",
        "\n",
        "    print(f\"\\n🔎 Deepfake Suspicion Score: {final_score:.2f} (0-1 scale)\")\n",
        "    if final_score > 0.7:\n",
        "        print(\"⚠ Likely deepfake.\")\n",
        "    elif final_score > 0.4:\n",
        "        print(\"⚠ Possibly suspicious.\")\n",
        "    else:\n",
        "        print(\"✅ Likely authentic.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF8Sv7hI231h",
        "outputId": "97804ced-ee82-474c-dc87-f14091add752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_inference(\"/veo3.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HY4qyQi3i1Q",
        "outputId": "6c3563f8-ddbd-4e39-e44f-faabea1b5033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Starting inference pipeline...\n",
            "[Step 1] Extracting audio and frames from video...\n",
            "Extracted 36 frames and saved audio as 'extracted_audio.wav'\n",
            "[Step 2] Extracting lip movement features from frames...\n",
            "Extracted mouth movement data from 36 frames\n",
            "[Step 3] Extracting MFCCs and audio energy...\n",
            "Extracted MFCC shape: (13, 223), Energy length: 1\n",
            "[Step 4] Calculating lip-sync inconsistency...\n",
            "Insufficient data for correlation calculation\n",
            "[Step 5] Running synthetic voice detection...\n",
            "Trained mock voice detection model\n",
            "Voice synthetic probability score: 0.580\n",
            "[Step 6] Calculating weighted suspicion score...\n",
            "Lip-sync score: 1.000, Voice score: 0.580\n",
            "\n",
            "🔎 Deepfake Suspicion Score: 0.83 (0-1 scale)\n",
            "⚠ Likely deepfake.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_inference(\"/WIN_20250526_14_50_09_Pro.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYm6R0234BF7",
        "outputId": "987a8f6c-f4ac-4450-dc18-58b1aea7fe87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Starting inference pipeline...\n",
            "[Step 1] Extracting audio and frames from video...\n",
            "Extracted 36 frames and saved audio as 'extracted_audio.wav'\n",
            "[Step 2] Extracting lip movement features from frames...\n",
            "Extracted mouth movement data from 36 frames\n",
            "[Step 3] Extracting MFCCs and audio energy...\n",
            "Extracted MFCC shape: (13, 222), Energy length: 1\n",
            "[Step 4] Calculating lip-sync inconsistency...\n",
            "Insufficient data for correlation calculation\n",
            "[Step 5] Running synthetic voice detection...\n",
            "Voice synthetic probability score: 0.600\n",
            "[Step 6] Calculating weighted suspicion score...\n",
            "Lip-sync score: 1.000, Voice score: 0.600\n",
            "\n",
            "🔎 Deepfake Suspicion Score: 0.84 (0-1 scale)\n",
            "⚠ Likely deepfake.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_inference(\"//News wrap in 30 Seconds, Full video follows at 9 PM on YouTube. Stay Tuned !.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gaboO9X6n_F",
        "outputId": "c80ca27f-81f0-4a70-c959-b0b0819741b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Starting inference pipeline...\n",
            "[Step 1] Extracting audio and frames from video...\n",
            "Extracted 175 frames and saved audio as 'extracted_audio.wav'\n",
            "[Step 2] Extracting lip movement features from frames...\n",
            "Extracted mouth movement data from 175 frames\n",
            "[Step 3] Extracting MFCCs and audio energy...\n",
            "Extracted MFCC shape: (13, 1088), Energy length: 1\n",
            "[Step 4] Calculating lip-sync inconsistency...\n",
            "Insufficient data for correlation calculation\n",
            "[Step 5] Running synthetic voice detection...\n",
            "Voice synthetic probability score: 0.560\n",
            "[Step 6] Calculating weighted suspicion score...\n",
            "Lip-sync score: 1.000, Voice score: 0.560\n",
            "\n",
            "🔎 Deepfake Suspicion Score: 0.82 (0-1 scale)\n",
            "⚠ Likely deepfake.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_inference(\"/videoplayback.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXFwLlwT7gUc",
        "outputId": "039f280a-4893-4e3e-e0fb-28cdc1468286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Starting inference pipeline...\n",
            "[Step 1] Extracting audio and frames from video...\n",
            "Extracted 177 frames and saved audio as 'extracted_audio.wav'\n",
            "[Step 2] Extracting lip movement features from frames...\n",
            "Extracted mouth movement data from 177 frames\n",
            "[Step 3] Extracting MFCCs and audio energy...\n",
            "Extracted MFCC shape: (13, 1101), Energy length: 1\n",
            "[Step 4] Calculating lip-sync inconsistency...\n",
            "Insufficient data for correlation calculation\n",
            "[Step 5] Running synthetic voice detection...\n",
            "Voice synthetic probability score: 0.580\n",
            "[Step 6] Calculating weighted suspicion score...\n",
            "Lip-sync score: 1.000, Voice score: 0.580\n",
            "\n",
            "🔎 Deepfake Suspicion Score: 0.83 (0-1 scale)\n",
            "⚠ Likely deepfake.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# deepfake_detector_v2.py\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import librosa\n",
        "from moviepy.editor import VideoFileClip\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import joblib\n",
        "import warnings\n",
        "import sys\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def safe_print(*args):\n",
        "    try:\n",
        "        print(*[str(a).encode('utf-8', 'replace').decode('utf-8') for a in args])\n",
        "    except UnicodeEncodeError:\n",
        "        print(\"⚠️ Skipped unsafe output due to encoding issue.\")\n",
        "\n",
        "def extract_audio_and_frames(video_path, audio_out='extracted_audio.wav', frame_dir='frames', fps=5):\n",
        "    safe_print(\"[Step 1] Extracting audio and frames from video...\")\n",
        "    clip = VideoFileClip(video_path)\n",
        "    clip.audio.write_audiofile(audio_out, logger=None)\n",
        "\n",
        "    if not os.path.exists(frame_dir):\n",
        "        os.makedirs(frame_dir)\n",
        "\n",
        "    duration = clip.duration\n",
        "    frame_count = 0\n",
        "    for i, t in enumerate(np.arange(0, duration, 1.0 / fps)):\n",
        "        frame = clip.get_frame(t)\n",
        "        frame_path = os.path.join(frame_dir, f\"frame_{i:03d}.jpg\")\n",
        "        cv2.imwrite(frame_path, cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
        "        frame_count += 1\n",
        "\n",
        "    safe_print(f\"Extracted {frame_count} frames and saved audio as '{audio_out}'\")\n",
        "    return audio_out, frame_dir\n",
        "\n",
        "def extract_lip_movement_features(frame_dir):\n",
        "    safe_print(\"[Step 2] Extracting lip movement features from frames...\")\n",
        "    mouth_movements = []\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "    for file in sorted(os.listdir(frame_dir)):\n",
        "        if file.endswith(\".jpg\"):\n",
        "            path = os.path.join(frame_dir, file)\n",
        "            img = cv2.imread(path)\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "            mouth_area = 0\n",
        "            for (x, y, w, h) in faces:\n",
        "                mouth_y = y + int(0.6 * h)\n",
        "                mouth_h = int(0.2 * h)\n",
        "                mouth = gray[mouth_y:mouth_y + mouth_h, x:x + w]\n",
        "                mouth_area = cv2.countNonZero(mouth)\n",
        "\n",
        "            mouth_movements.append(mouth_area)\n",
        "\n",
        "    safe_print(f\"Extracted mouth movement data from {len(mouth_movements)} frames\")\n",
        "    return mouth_movements\n",
        "\n",
        "def extract_audio_features(audio_path, sr=16000, fps=5):\n",
        "    safe_print(\"[Step 3] Extracting MFCCs and audio energy...\")\n",
        "    y, sr = librosa.load(audio_path, sr=sr)\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "\n",
        "    hop_length = int(sr / fps)\n",
        "    frame_energy = [\n",
        "        np.sum(np.square(y[i:i + hop_length]))\n",
        "        for i in range(0, len(y), hop_length)\n",
        "    ]\n",
        "\n",
        "    safe_print(f\"Extracted MFCC shape: {mfccs.shape}, Energy length: {len(frame_energy)}\")\n",
        "    return mfccs, frame_energy\n",
        "\n",
        "def calculate_lipsync_inconsistency(mouth_movements, audio_energy):\n",
        "    safe_print(\"[Step 4] Calculating lip-sync inconsistency...\")\n",
        "    length = min(len(mouth_movements), len(audio_energy))\n",
        "    if length < 2:\n",
        "        safe_print(\"Insufficient data for correlation calculation\")\n",
        "        return 1.0\n",
        "\n",
        "    mouth_movements = np.array(mouth_movements[:length])\n",
        "    audio_energy = np.array(audio_energy[:length])\n",
        "    corr, _ = pearsonr(mouth_movements, audio_energy)\n",
        "    return 1 - corr\n",
        "\n",
        "def synthetic_voice_detection(mfccs):\n",
        "    safe_print(\"[Step 5] Running synthetic voice detection...\")\n",
        "    mean_mfcc = np.mean(mfccs, axis=1)\n",
        "    std_mfcc = np.std(mfccs, axis=1)\n",
        "    features = np.concatenate((mean_mfcc, std_mfcc)).reshape(1, -1)\n",
        "\n",
        "    if os.path.exists(\"voice_model.pkl\"):\n",
        "        clf = joblib.load(\"voice_model.pkl\")\n",
        "    else:\n",
        "        safe_print(\"Trained mock voice detection model\")\n",
        "        X_dummy = np.random.rand(20, 26)\n",
        "        y_dummy = [0]*10 + [1]*10\n",
        "        clf = RandomForestClassifier()\n",
        "        clf.fit(X_dummy, y_dummy)\n",
        "        joblib.dump(clf, \"voice_model.pkl\")\n",
        "\n",
        "    prob = clf.predict_proba(features)[0][1]\n",
        "    safe_print(f\"Voice synthetic probability score: {prob:.3f}\")\n",
        "    return prob\n",
        "\n",
        "def calculate_overall_score(lipsync_score, voice_score, w1=0.6, w2=0.4):\n",
        "    safe_print(\"[Step 6] Calculating weighted suspicion score...\")\n",
        "    safe_print(f\"Lip-sync score: {lipsync_score:.3f}, Voice score: {voice_score:.3f}\")\n",
        "    return w1 * lipsync_score + w2 * voice_score\n",
        "\n",
        "def run_inference(video_path):\n",
        "    safe_print(\"\\n⏳ Starting inference pipeline...\")\n",
        "    audio, frames = extract_audio_and_frames(video_path)\n",
        "    lips = extract_lip_movement_features(frames)\n",
        "    mfccs, energy = extract_audio_features(audio)\n",
        "    lip_score = calculate_lipsync_inconsistency(lips, energy)\n",
        "    voice_score = synthetic_voice_detection(mfccs)\n",
        "    final_score = calculate_overall_score(lip_score, voice_score)\n",
        "\n",
        "    safe_print(f\"\\n🔎 Deepfake Suspicion Score: {final_score:.2f} (0-1 scale)\")\n",
        "    if final_score > 0.7:\n",
        "        safe_print(\"⚠️ Likely deepfake.\")\n",
        "    elif final_score > 0.4:\n",
        "        safe_print(\"⚠️ Possibly suspicious.\")\n",
        "    else:\n",
        "        safe_print(\"✅ Likely authentic.\")\n"
      ],
      "metadata": {
        "id": "lAbfvv7HCKgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_inference(\"/videoplayback.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV0J04waChvw",
        "outputId": "9f7753cf-6167-4793-8aa6-7fba6df6c5ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏳ Starting inference pipeline...\n",
            "[Step 1] Extracting audio and frames from video...\n",
            "Extracted 177 frames and saved audio as 'extracted_audio.wav'\n",
            "[Step 2] Extracting lip movement features from frames...\n",
            "Extracted mouth movement data from 177 frames\n",
            "[Step 3] Extracting MFCCs and audio energy...\n",
            "Extracted MFCC shape: (13, 1101), Energy length: 177\n",
            "[Step 4] Calculating lip-sync inconsistency...\n",
            "[Step 5] Running synthetic voice detection...\n",
            "Voice synthetic probability score: 0.580\n",
            "[Step 6] Calculating weighted suspicion score...\n",
            "Lip-sync score: 0.971, Voice score: 0.580\n",
            "\n",
            "🔎 Deepfake Suspicion Score: 0.81 (0-1 scale)\n",
            "⚠️ Likely deepfake.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_inference(\"//News wrap in 30 Seconds, Full video follows at 9 PM on YouTube. Stay Tuned !.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1Ce-Ls2DvqA",
        "outputId": "906a5e3a-1683-4c4a-8769-4397202c4855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏳ Starting inference pipeline...\n",
            "[Step 1] Extracting audio and frames from video...\n",
            "Extracted 175 frames and saved audio as 'extracted_audio.wav'\n",
            "[Step 2] Extracting lip movement features from frames...\n",
            "Extracted mouth movement data from 177 frames\n",
            "[Step 3] Extracting MFCCs and audio energy...\n",
            "Extracted MFCC shape: (13, 1088), Energy length: 175\n",
            "[Step 4] Calculating lip-sync inconsistency...\n",
            "[Step 5] Running synthetic voice detection...\n",
            "Voice synthetic probability score: 0.560\n",
            "[Step 6] Calculating weighted suspicion score...\n",
            "Lip-sync score: 0.918, Voice score: 0.560\n",
            "\n",
            "🔎 Deepfake Suspicion Score: 0.77 (0-1 scale)\n",
            "⚠️ Likely deepfake.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_inference(\"/WIN_20250526_14_50_09_Pro.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dngai3gqD35d",
        "outputId": "67605813-6aa7-4407-8f3c-74da0bd6e048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏳ Starting inference pipeline...\n",
            "[Step 1] Extracting audio and frames from video...\n",
            "Extracted 36 frames and saved audio as 'extracted_audio.wav'\n",
            "[Step 2] Extracting lip movement features from frames...\n",
            "Extracted mouth movement data from 177 frames\n",
            "[Step 3] Extracting MFCCs and audio energy...\n",
            "Extracted MFCC shape: (13, 222), Energy length: 222\n",
            "[Step 4] Calculating lip-sync inconsistency...\n",
            "Lip-sync correlation: -0.631, Inconsistency Score: 1.631\n",
            "[Step 5] Running synthetic voice detection...\n",
            "Voice synthetic probability score: 0.600\n",
            "[Step 6] Calculating weighted suspicion score...\n",
            "Lip-sync score: 1.631, Voice score: 0.600\n",
            "\n",
            "🔎 Deepfake Suspicion Score: 1.22 (0-1 scale)\n",
            "⚠ Likely deepfake.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_inference(\"/veo3.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXtVGq7dEJST",
        "outputId": "588b463c-2437-4b50-f51f-24d7bf7c16a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏳ Starting inference pipeline...\n",
            "[Step 1] Extracting audio and frames from video...\n",
            "Extracted 36 frames and saved audio as 'extracted_audio.wav'\n",
            "[Step 2] Extracting lip movement features from frames...\n",
            "Extracted mouth movement data from 177 frames\n",
            "[Step 3] Extracting MFCCs and audio energy...\n",
            "Extracted MFCC shape: (13, 223), Energy length: 223\n",
            "[Step 4] Calculating lip-sync inconsistency...\n",
            "Lip-sync correlation: -0.179, Inconsistency Score: 1.179\n",
            "[Step 5] Running synthetic voice detection...\n",
            "Voice synthetic probability score: 0.580\n",
            "[Step 6] Calculating weighted suspicion score...\n",
            "Lip-sync score: 1.179, Voice score: 0.580\n",
            "\n",
            "🔎 Deepfake Suspicion Score: 0.94 (0-1 scale)\n",
            "⚠ Likely deepfake.\n"
          ]
        }
      ]
    }
  ]
}